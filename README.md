# Gen Model Identifier

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

The rise of advanced language models means we need to be better at telling apart human-written and AI-created text. Taking a cue from GPTZero, an app that tries to spot AI-produced content, this goes a step further. It offers a range of tools to guess which specific (publicly known) language model might have crafted a particular piece of text.

## Installation

Install the package in editable mode.

```
$ pip install -e .
```

## Usages

### 1.Perplexity-based Ranking

Perplexity is a common metric used in natural language generation to measure the performance of an LM. Roughly speaking, perplexity is the exponentiation of cross entropy. The bottom line is that lower perplexity indicates higher probability of the text being generated by that model.

This provides a perplexity-based ranking function as shown below.

```python
from gen_model_identifier.perplexity import rank_by_perplexity

candidate_models = [
    "gpt2",
    "distilgpt2",
    "facebook/opt-350m",
    "lvwerra/gpt2-imdb",
]

text = (
    "Brad Cooper, who plays the lead character, is a very good actor. He is a very good"
)

model2perplexity = rank_by_perplexity(text, candidate_models)
```

`model2perplexity` is a dictionary of perplexity scores for each language model in sorted order.

```python
{
    'lvwerra/gpt2-imdb': 8.249064445495605, 
    'gpt2': 12.83916187286377, 
    'facebook/opt-350m': 16.77145767211914, 
    'distilgpt2': 20.15663719177246
}
```

This toy example was indeed generated with `'lvwerra/gpt2-imdb'`, which is a standard `'gpt2'` model fine-tuned on the IMDB dataset. It can thus be leveraged to distinguish between not only disparate models, but also an upstream model and its fine-tuned variant.


Released under the [MIT License](License).